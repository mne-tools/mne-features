{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Use scikit-learn GridSearchCV with FeatureExtractor for setting parameters\n\nThe example shows how :class:`~sklearn.model_selection.GridSearchCV`\ncan be used for parameter tuning in a pipeline which sequentially\ncombines feature extraction (with\n:class:`mne_features.feature_extraction.FeatureExtractor`),\ndata standardization (with :class:`~sklearn.preprocessing.StandardScaler`)\nand classification (with :class:`~sklearn.linear_model.LogisticRegression`).\n\nThe code for this example is based on the method proposed in:\n\nJean-Baptiste SCHIRATTI, Jean-Eudes LE DOUGET, Michel LE VAN QUYEN,\nSlim ESSID, Alexandre GRAMFORT,\n\"An ensemble learning approach to detect epileptic seizures from long\nintracranial EEG recordings\"\nProc. IEEE ICASSP Conf. 2018\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This example is for illustration purposes, as other methods\n    may lead to better performance on such a dataset (classification\n    of auditory vs. visual stimuli).</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Jean-Baptiste Schiratti <jean.baptiste.schiratti@gmail.com>\n#         Guillaume Corda <guillaume.corda@telecom-paristech.fr>\n#         Alexandre Gramfort <alexandre.gramfort@inria.fr>\n# License: BSD 3 clause\n\nimport mne\nimport numpy as np\nimport pandas as pd\nfrom mne.datasets import sample\nfrom mne_features.feature_extraction import FeatureExtractor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import (GridSearchCV, cross_val_score,\n                                     StratifiedKFold)\nfrom sklearn.pipeline import Pipeline\n\nprint(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us import the data using MNE-Python and epoch it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nraw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\nevent_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\ntmin, tmax = -0.2, 0.5\nevent_id = dict(aud_l=1, vis_l=3)\n\n# Setup for reading the raw data\nraw = mne.io.read_raw_fif(raw_fname, preload=True)\nraw.filter(.5, None, fir_design='firwin')\nevents = mne.read_events(event_fname)\npicks = mne.pick_types(raw.info, meg='grad', eeg=False)\n\n# Read epochs\nepochs = mne.Epochs(raw, events, event_id, tmin, tmax, picks=picks, proj=True,\n                    baseline=None, preload=True)\nlabels = epochs.events[:, -1]\n\n# get MEG and EEG data\ndata = epochs.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare for the classification task:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline([('fe', FeatureExtractor(sfreq=raw.info['sfreq'],\n                                         selected_funcs=['app_entropy',\n                                                         'mean'])),\n                 ('scaler', StandardScaler()),\n                 ('clf', LogisticRegression(random_state=42, solver='lbfgs'))])\nskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\ny = labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cross-validation accuracy score with default parameters (emb = 2, by default\nfor `compute_app_entropy`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = cross_val_score(pipe, data, y, cv=skf)\nprint('Cross-validation accuracy score (with default parameters) = %1.3f '\n      '(+/- %1.5f)' % (np.mean(scores), np.std(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimization of features extraction optional parameters:\nHere, only the embedding dimension parameter of\n:func:`mne_features.univariate.compute_app_entropy` is optimized using\nGridSearchCV.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params_grid = {'fe__app_entropy__emb': np.arange(2, 5)}\n\ncv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\ngs = GridSearchCV(estimator=pipe, param_grid=params_grid,\n                  cv=cv, n_jobs=1,\n                  return_train_score=True)\ngs.fit(data, y)\n\n# Best parameters obtained with GridSearchCV:\nprint(gs.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scores with all parameter values:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = pd.DataFrame(gs.cv_results_)\nprint(scores[['params', 'mean_test_score', 'mean_train_score']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cross-validation accuracy score with optimized parameters:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gs_best = gs.best_estimator_\nnew_scores = cross_val_score(gs_best, data, y, cv=skf)\n\nprint('Cross-validation accuracy score (with optimized parameters) = %1.3f '\n      '(+/- %1.5f)' % (np.mean(new_scores), np.std(new_scores)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}